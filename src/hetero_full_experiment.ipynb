{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML441 Assignment 4\n",
    "## Charles de Kock - 26023830"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from contextlib import redirect_stdout\n",
    "from autorank import autorank, plot_stats\n",
    "import scikit_posthocs as sp\n",
    "import io\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef, accuracy_score\n",
    "import hashlib\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 40\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxillary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_file(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        return json.load(file)\n",
    "    \n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        try:\n",
    "            return super().default(obj)\n",
    "        except TypeError:\n",
    "            pass\n",
    "        if hasattr(obj, '__dict__'):\n",
    "            return obj.__dict__\n",
    "        elif hasattr(obj, '__str__'):\n",
    "            return str(obj)\n",
    "        else:\n",
    "            return f\"<non-serializable: {type(obj).__name__}>\"\n",
    "\n",
    "def save_json(data, path, indent=4):\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(data, f, indent=indent, cls=CustomJSONEncoder)\n",
    "\n",
    "def hash_dict(d):\n",
    "    dict_str = json.dumps(d, sort_keys=True)\n",
    "    return hashlib.sha256(dict_str.encode('utf-8')).hexdigest()\n",
    "\n",
    "def avg_results(data, n_folds=10):\n",
    "    out = {}\n",
    "    for key in list(data.keys()):\n",
    "        accs = []\n",
    "        f1s = []\n",
    "        for i in range(n_folds):\n",
    "            temp = data[key]['results'][f'fold_{i}']\n",
    "            accs.append(temp['acc'])\n",
    "            f1s.append(temp['f1'])\n",
    "        out[key] =  {\n",
    "            'mean_acc': float(np.mean(accs)),\n",
    "            'std_acc': float(np.std(accs)),\n",
    "            'mean_f1': float(np.mean(f1s)),\n",
    "            'std_f1': float(np.std(f1s))\n",
    "        }\n",
    "    return out\n",
    "\n",
    "def sort_results(full_data, key, show=False, top_n=10):\n",
    "    avg_data = avg_results(full_data)\n",
    "    out = sorted(avg_data.keys(), key=lambda k: avg_data[k][f'mean_{key}'], reverse=True)\n",
    "    if show == True:\n",
    "        for r in out[:top_n]:\n",
    "            print(f\"ID: {r} Parameters: {full_data[r]['params']} -> {key}: {avg_data[r]['mean_' + key]} ± {avg_data[r]['std_' + key]}\")\n",
    "    return out\n",
    "\n",
    "def handle_outliers_iqr(df, threshold=2):\n",
    "    df_clean = df.copy()\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    for col in numeric_cols:\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - threshold * IQR\n",
    "        upper_bound = Q3 + threshold * IQR\n",
    "        df_clean[col] = np.clip(df[col], lower_bound, upper_bound)\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    y = df['diagnosis'].map({'B': 0, 'M': 1})\n",
    "    X = df.drop(columns=['diagnosis', 'gender', 'id', 'perimeter_mean', 'perimeter_se', 'perimeter_worst', 'area_mean', 'area_se', 'area_worst'])\n",
    "    X = handle_outliers_iqr(X)\n",
    "    imputer = SimpleImputer(strategy='median')\n",
    "    X_imputed = imputer.fit_transform(X)\n",
    "    X = pd.DataFrame(X_imputed, columns=X.columns, index=X.index)\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/breastCancer.csv', delimiter='\\t', na_values='?')\n",
    "X, y = preprocess(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_folds(X, y, n_folds = 10):\n",
    "    kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    folds = []\n",
    "    splits = kf.split(X, y)\n",
    "    for train_index, val_index in splits:\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        folds.append({'Xt': X_train, 'Xv': X_val, 'yt': y_train, 'yv': y_val})\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = generate_folds(X, y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_lr(fold, params):\n",
    "    model = LogisticRegression(\n",
    "        penalty=params['penalty'],\n",
    "        C=params['C'],\n",
    "        solver=params['solver'],\n",
    "        max_iter=params['max_iter'],\n",
    "        class_weight=params['class_weight'],\n",
    "        fit_intercept=params['fit_intercept'],\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(fold['Xt'], fold['yt'])\n",
    "    y_pred = model.predict(fold['Xv'])\n",
    "    f1 = f1_score(fold['yv'], y_pred, average='binary')\n",
    "    acc = accuracy_score(fold['yv'], y_pred)\n",
    "    \n",
    "    return {'acc': acc, 'f1': f1}\n",
    "\n",
    "def create_param_dicts(**kwargs):\n",
    "    keys = list(kwargs.keys())\n",
    "    values = list(kwargs.values())\n",
    "    \n",
    "    param_dicts = []\n",
    "    for combination in itertools.product(*values):\n",
    "        param_dict = dict(zip(keys, combination))\n",
    "        \n",
    "        # Compatibility filtering\n",
    "        penalty = param_dict['penalty']\n",
    "        solver = param_dict['solver']\n",
    "\n",
    "        # Invalid combinations to skip\n",
    "        if solver == 'lbfgs' and penalty not in ['l2', 'none']:\n",
    "            continue\n",
    "        if solver == 'saga' and penalty not in ['l1', 'l2', 'elasticnet']:\n",
    "            continue\n",
    "        if solver == 'liblinear' and penalty not in ['l1', 'l2']:\n",
    "            continue\n",
    "        if solver == 'newton-cg' and penalty not in ['l2', 'none']:\n",
    "            continue\n",
    "        if solver == 'sag' and penalty not in ['l2', 'none']:\n",
    "            continue\n",
    "        \n",
    "        param_dicts.append(param_dict)\n",
    "    \n",
    "    return param_dicts\n",
    "\n",
    "def run_experiment_lr(param_dicts, folds):\n",
    "    out = {}\n",
    "    for p in tqdm(param_dicts):\n",
    "        entry = {}\n",
    "        entry['params'] = p\n",
    "        data = {}\n",
    "        for i in range(len(folds)):\n",
    "            data[f'fold_{i}'] = eval_lr(folds[i], p)\n",
    "        entry['results'] = data\n",
    "        out[hash_dict(p)] = entry\n",
    "    return out\n",
    "\n",
    "lr_param_dicts = create_param_dicts(\n",
    "    penalty=['l1', 'l2', None],\n",
    "    solver=['lbfgs', 'saga', 'liblinear'],\n",
    "    C=[0.01, 0.1, 1, 10, 100],\n",
    "    class_weight=['balanced', None],\n",
    "    fit_intercept=[True, False],\n",
    "    max_iter=[200, 500, 1000]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 300/300 [03:34<00:00,  1.40it/s]\n"
     ]
    }
   ],
   "source": [
    "lr_results = run_experiment_lr(lr_param_dicts, folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(lr_results, '../../results/hetero/lr_results.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_results = load_json_file('../../results/hetero/lr_results.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 742b2aa0a59fc529151f4695d0eb79fe5bdeaae12be92e4f504d0705a754e1f2 Parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 100, 'class_weight': 'balanced', 'fit_intercept': True, 'max_iter': 1000} -> acc: 0.9595551378446114 ± 0.020889413280441495\n",
      "ID: 534d5a0882b30ad2a1a101f1a71d6a5f3980fc3bc5cfead616dbf974697e0507 Parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 100, 'class_weight': 'balanced', 'fit_intercept': True, 'max_iter': 500} -> acc: 0.9577694235588972 ± 0.022626249382872148\n",
      "ID: 8b2cf4d4021c8801bf0a60a1817c6efa66b21cdfb6529693d654138a1d22afc0 Parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 100, 'class_weight': 'balanced', 'fit_intercept': True, 'max_iter': 200} -> acc: 0.9577694235588972 ± 0.022626249382872148\n",
      "ID: b24bd949615fe7636729a912e62c75e016e7b957320aa94078d4c839181d9896 Parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 100, 'class_weight': 'balanced', 'fit_intercept': True, 'max_iter': 500} -> acc: 0.9577694235588972 ± 0.022626249382872148\n",
      "ID: 7505941b92933c05d6bef06b630567874f12a2bc965ccc48857c17feaec7efc2 Parameters: {'penalty': 'l2', 'solver': 'liblinear', 'C': 100, 'class_weight': 'balanced', 'fit_intercept': True, 'max_iter': 1000} -> acc: 0.9577694235588972 ± 0.022626249382872148\n",
      "ID: 85b5595fd373f60725ab9e9c104d04d3c09791c737e270d119ad7b3ac307e65b Parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 100, 'class_weight': None, 'fit_intercept': True, 'max_iter': 500} -> acc: 0.9542606516290727 ± 0.02120165954346946\n",
      "ID: 86d3e0b78a80df7728ab4de79c4a691551580c3cb027815f48aed595c7289e18 Parameters: {'penalty': 'l2', 'solver': 'lbfgs', 'C': 100, 'class_weight': None, 'fit_intercept': True, 'max_iter': 1000} -> acc: 0.9542606516290727 ± 0.02120165954346946\n",
      "ID: 8b4e384ab25bf303ab7440b5a17b0e7c58b25765b2dfb97c2c78470dc7d098a6 Parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 10, 'class_weight': None, 'fit_intercept': True, 'max_iter': 200} -> acc: 0.9525375939849624 ± 0.022284656207512958\n",
      "ID: 2efc1718d87a229511e9445c80ab3a331e470a118a2a547b6922e050059a27a6 Parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 10, 'class_weight': None, 'fit_intercept': True, 'max_iter': 500} -> acc: 0.9525375939849624 ± 0.022284656207512958\n",
      "ID: 3e8de270578a7492782e2e64f7a08e48c7f40c0cd7193fb78239ae54cbe83ae4 Parameters: {'penalty': 'l1', 'solver': 'liblinear', 'C': 10, 'class_weight': None, 'fit_intercept': True, 'max_iter': 1000} -> acc: 0.9525375939849624 ± 0.022284656207512958\n"
     ]
    }
   ],
   "source": [
    "best_config_keys = sort_results(lr_results, 'acc', show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_dt(fold, params):\n",
    "    model = DecisionTreeClassifier(\n",
    "        criterion=params['criterion'],\n",
    "        max_depth=params['max_depth'],\n",
    "        min_samples_split=params['min_samples_split'],\n",
    "        min_samples_leaf=params['min_samples_leaf'],\n",
    "        max_features=params['max_features'],\n",
    "        class_weight=params['class_weight'],\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    model.fit(fold['Xt'], fold['yt'])\n",
    "    y_pred = model.predict(fold['Xv'])\n",
    "    f1 = f1_score(fold['yv'], y_pred, average='binary')\n",
    "    acc = accuracy_score(fold['yv'], y_pred)\n",
    "    \n",
    "    return {'acc': acc, 'f1': f1}\n",
    "\n",
    "def create_param_dicts(**kwargs):\n",
    "    keys = list(kwargs.keys())\n",
    "    values = list(kwargs.values())\n",
    "    \n",
    "    param_dicts = []\n",
    "    for combination in itertools.product(*values):\n",
    "        param_dict = dict(zip(keys, combination))\n",
    "        param_dicts.append(param_dict)\n",
    "    \n",
    "    return param_dicts\n",
    "\n",
    "def run_experiment_dt(param_dicts, folds):\n",
    "    out = {}\n",
    "    for p in tqdm(param_dicts):\n",
    "        entry = {}\n",
    "        entry['params'] = p\n",
    "        data = {}\n",
    "        for i in range(len(folds)):\n",
    "            data[f'fold_{i}'] = eval_dt(folds[i], p)\n",
    "        entry['results'] = data\n",
    "        out[hash_dict(p)] = entry\n",
    "    return out\n",
    "\n",
    "# Define Decision Tree hyperparameter grid\n",
    "dt_param_dicts = create_param_dicts(\n",
    "    criterion=['gini', 'entropy', 'log_loss'],\n",
    "    max_depth=[None, 5, 10, 20, 30],\n",
    "    min_samples_split=[2, 5, 10],\n",
    "    min_samples_leaf=[1, 2, 4],\n",
    "    max_features=[None, 'sqrt', 'log2'],\n",
    "    class_weight=[None, 'balanced']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 810/810 [01:30<00:00,  8.98it/s]\n"
     ]
    }
   ],
   "source": [
    "dt_results = run_experiment_dt(dt_param_dicts, folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(dt_results, '../../results/hetero/dt_results.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_results = load_json_file('../../results/hetero/dt_results.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: baa80c373866d67f92828a5888f7d2adc7337fa5d3b22f087237aa3606f01210 Parameters: {'criterion': 'gini', 'max_depth': None, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'class_weight': 'balanced'} -> acc: 0.9471804511278196 ± 0.02396082057458112\n",
      "ID: f1cd5f5421b969ab607ec0228c95fd652742f83a940c8dd99da3fd92b38f6b53 Parameters: {'criterion': 'gini', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'class_weight': 'balanced'} -> acc: 0.9471804511278196 ± 0.02396082057458112\n",
      "ID: 9a18da355ed0988a9b68883cabb8543804073654e5231ca5c42b283a8e4bc6d0 Parameters: {'criterion': 'gini', 'max_depth': 20, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'class_weight': 'balanced'} -> acc: 0.9471804511278196 ± 0.02396082057458112\n",
      "ID: 42595413cd107cb78b04334698c2127b40e35fbc40ad1d8cf25bfc330d1da672 Parameters: {'criterion': 'gini', 'max_depth': 30, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 'sqrt', 'class_weight': 'balanced'} -> acc: 0.9471804511278196 ± 0.02396082057458112\n",
      "ID: 4f55561c9d1a2d44ee886847fa2698a3484b0ca39892ad7d6860f5f0b5ed0c62 Parameters: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'class_weight': 'balanced'} -> acc: 0.9454887218045114 ± 0.032837101913689985\n",
      "ID: 3be65b3963373bac5a62cc7f8f29e3c32aed9b86789292bbf371ff53ff48f337 Parameters: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 2, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'class_weight': 'balanced'} -> acc: 0.9437343358395991 ± 0.029208749511853135\n",
      "ID: 2f5018b659b71dc0a9e03e559fc20f395f78b9401aa402f4835213dba84e95b2 Parameters: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 4, 'max_features': 'sqrt', 'class_weight': 'balanced'} -> acc: 0.9437343358395991 ± 0.029208749511853135\n",
      "ID: 68b4b944242a829988c561e99065798fd8aaa6bd0d9286eeb86821add35a4f26 Parameters: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'log2', 'class_weight': 'balanced'} -> acc: 0.9420426065162907 ± 0.034203008987993506\n",
      "ID: 9ff24cdc1436fde8203cc280a5bcd5db1c063e4306805f5d58bb599daab646f2 Parameters: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 5, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'class_weight': 'balanced'} -> acc: 0.9402568922305765 ± 0.026233629502532642\n",
      "ID: 6770b3d3c6c2cbc5dd2e6597b93a5aa5d91a681cf571f7d14888caca5d07ed06 Parameters: {'criterion': 'gini', 'max_depth': 5, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': None, 'class_weight': 'balanced'} -> acc: 0.9402568922305765 ± 0.03056849564480799\n"
     ]
    }
   ],
   "source": [
    "best_config_keys = sort_results(dt_results, 'acc', show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_knn(fold, params):\n",
    "    model = KNeighborsClassifier(\n",
    "        n_neighbors=params['n_neighbors'],\n",
    "        weights=params['weights'],\n",
    "        algorithm=params['algorithm'],\n",
    "        p=params['p'],\n",
    "        metric='minkowski',\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(fold['Xt'], fold['yt'])\n",
    "    y_pred = model.predict(fold['Xv'])\n",
    "    f1 = f1_score(fold['yv'], y_pred, average='binary')\n",
    "    acc = accuracy_score(fold['yv'], y_pred)\n",
    "    \n",
    "    return {'acc': acc, 'f1': f1}\n",
    "\n",
    "def create_param_dicts(**kwargs):\n",
    "    keys = list(kwargs.keys())\n",
    "    values = list(kwargs.values())\n",
    "    \n",
    "    param_dicts = []\n",
    "    for combination in itertools.product(*values):\n",
    "        param_dict = dict(zip(keys, combination))\n",
    "        param_dicts.append(param_dict)\n",
    "    \n",
    "    return param_dicts\n",
    "\n",
    "def run_experiment_knn(param_dicts, folds):\n",
    "    out = {}\n",
    "    for p in tqdm(param_dicts):\n",
    "        entry = {}\n",
    "        entry['params'] = p\n",
    "        data = {}\n",
    "        for i in range(len(folds)):\n",
    "            data[f'fold_{i}'] = eval_knn(folds[i], p)\n",
    "        entry['results'] = data\n",
    "        out[hash_dict(p)] = entry\n",
    "    return out\n",
    "\n",
    "# Define KNN hyperparameter grid\n",
    "knn_param_dicts = create_param_dicts(\n",
    "    n_neighbors=[3, 5, 7, 9, 11, 15, 31, 51],\n",
    "    weights=['uniform', 'distance'],        \n",
    "    algorithm=['brute'],  \n",
    "    p=[1, 2, 3]                              \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [00:05<00:00,  9.04it/s]\n"
     ]
    }
   ],
   "source": [
    "knn_results = run_experiment_knn(knn_param_dicts, folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(knn_results, '../../results/hetero/knn_results.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_results = load_json_file('../../results/hetero/knn_results.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 9bd2fe001a173200956ed51a37c44c9ac8cf3fab687971a4c39e4e5eabc480c3 Parameters: {'n_neighbors': 31, 'weights': 'uniform', 'algorithm': 'brute', 'p': 1} -> acc: 0.9384711779448622 ± 0.02860026904771743\n",
      "ID: d7642812767e936bed7016c498e251eb4fd98b0e3dedfd61ca175967238e4a43 Parameters: {'n_neighbors': 11, 'weights': 'uniform', 'algorithm': 'brute', 'p': 1} -> acc: 0.9349624060150378 ± 0.023633766279937168\n",
      "ID: d4c19b5daf05a0a4dbea1ba76f60af40ff401ef7fcc0bca1665130b725f8d5df Parameters: {'n_neighbors': 11, 'weights': 'distance', 'algorithm': 'brute', 'p': 1} -> acc: 0.9349624060150378 ± 0.026108805279635883\n",
      "ID: b6b8076e917c868ba885b720fbcad510f239ab40c273d7b1f2cb734dbdab1477 Parameters: {'n_neighbors': 31, 'weights': 'distance', 'algorithm': 'brute', 'p': 1} -> acc: 0.9332080200501254 ± 0.02697031829822565\n",
      "ID: 4ecd3ba5c7cd2a437e0bbd07baea897134f58238dec7548bd576cefe94d32af0 Parameters: {'n_neighbors': 9, 'weights': 'uniform', 'algorithm': 'brute', 'p': 1} -> acc: 0.9332080200501253 ± 0.025803888599007348\n",
      "ID: 078e5d52136572c562153ff792365b670ac8086e87864e7706ec9c1da6b4064c Parameters: {'n_neighbors': 9, 'weights': 'distance', 'algorithm': 'brute', 'p': 1} -> acc: 0.9332080200501253 ± 0.02329647746494594\n",
      "ID: a73260a81ad031c311c6842bb029bfbc98d109d56e358de5187290f36323d255 Parameters: {'n_neighbors': 7, 'weights': 'uniform', 'algorithm': 'brute', 'p': 1} -> acc: 0.9331766917293234 ± 0.028191328710099196\n",
      "ID: 08cfeb0b495b893a7773582b4cb92ecc2d6cef4256d898e475bcc4b2fd78fd76 Parameters: {'n_neighbors': 7, 'weights': 'distance', 'algorithm': 'brute', 'p': 1} -> acc: 0.931422305764411 ± 0.02992943548641954\n",
      "ID: 9f5224b85152c8d819e4d5a86b8d0fc0c9424ad0e170aa3cdfd605d20412eba2 Parameters: {'n_neighbors': 15, 'weights': 'uniform', 'algorithm': 'brute', 'p': 1} -> acc: 0.9296992481203008 ± 0.02718143039102288\n",
      "ID: 9bb1ece108fe9c60840512a6fb10b4637580b4e167b7c377e485e6897f2df3a2 Parameters: {'n_neighbors': 5, 'weights': 'uniform', 'algorithm': 'brute', 'p': 1} -> acc: 0.9296679197994988 ± 0.0314743619856364\n"
     ]
    }
   ],
   "source": [
    "best_config_keys = sort_results(knn_results, 'acc', show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_stack(fold, params, lr, knn, dt, key='acc'):\n",
    "\n",
    "    lr_configs = sort_results(lr, key, show=False)\n",
    "    knn_configs = sort_results(knn, key, show=False)\n",
    "    dt_configs = sort_results(dt, key, show=False)\n",
    "\n",
    "    estimators = []\n",
    "    counter = 0\n",
    "    for _ in range(params['nr_repeats']):\n",
    "        for i in range(params['top_n']):\n",
    "            estimators.append((\n",
    "                f'lr_{counter}',\n",
    "                LogisticRegression(**lr[lr_configs[i]]['params'], random_state=42, n_jobs=-1)\n",
    "            ))\n",
    "            estimators.append((\n",
    "                f'knn_{counter}',\n",
    "                KNeighborsClassifier(**knn[knn_configs[i]]['params'], metric='minkowski', n_jobs=-1)\n",
    "            ))\n",
    "            estimators.append((\n",
    "                f'dt_{counter}',\n",
    "                DecisionTreeClassifier(**dt[dt_configs[i]]['params'], random_state=42)\n",
    "            ))\n",
    "            counter += 1\n",
    "\n",
    "    meta_model = LogisticRegression(max_iter=500)\n",
    "    stack_model = StackingClassifier(\n",
    "        estimators=estimators,\n",
    "        final_estimator=meta_model,\n",
    "        cv=None\n",
    "    )\n",
    "    \n",
    "    stack_model.fit(fold['Xt'], fold['yt'])\n",
    "    y_pred = stack_model.predict(fold['Xv'])\n",
    "    f1 = f1_score(fold['yv'], y_pred, average='binary')\n",
    "    acc = accuracy_score(fold['yv'], y_pred)\n",
    "    \n",
    "    return {'acc': acc, 'f1': f1}\n",
    "\n",
    "def create_param_dicts(**kwargs):\n",
    "    keys = list(kwargs.keys())\n",
    "    values = list(kwargs.values())\n",
    "    \n",
    "    param_dicts = []\n",
    "    for combination in itertools.product(*values):\n",
    "        param_dict = dict(zip(keys, combination))\n",
    "        param_dicts.append(param_dict)\n",
    "    \n",
    "    return param_dicts\n",
    "\n",
    "def run_experiment_stack(param_dicts, folds, lr, knn, dt):\n",
    "    out = {}\n",
    "    for p in tqdm(param_dicts):\n",
    "        entry = {}\n",
    "        entry['params'] = p\n",
    "        data = {}\n",
    "        for i in range(len(folds)):\n",
    "            data[f'fold_{i}'] = eval_stack(folds[i], p, lr, knn, dt)\n",
    "        entry['results'] = data\n",
    "        out[hash_dict(p)] = entry\n",
    "    return out\n",
    "\n",
    "# Define KNN hyperparameter grid\n",
    "stack_param_dicts = create_param_dicts(\n",
    "    nr_repeats=[1, 3, 5, 7, 9, 15, 25, 45],\n",
    "    top_n=[1, 2, 3, 4, 5]                             \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40/40 [1:39:36<00:00, 149.41s/it]\n"
     ]
    }
   ],
   "source": [
    "stack_results = run_experiment_stack(stack_param_dicts, folds, lr_results, knn_results, dt_results)\n",
    "save_json(stack_results, '../../results/hetero/stack_results.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(stack_results, '../../results/hetero/stack_results.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: c2f20785b52109c1166bf566ebc0e8001bff2fe475ea8fd5395e79845ac5d18c Parameters: {'nr_repeats': 15, 'top_n': 1} -> acc: 0.9648182957393482 ± 0.01763984772966321\n",
      "ID: 8f368a3ce4db526885e60d14194da6f02605d31c7b07b24ae0a795bfaa8b0466 Parameters: {'nr_repeats': 25, 'top_n': 1} -> acc: 0.9648182957393482 ± 0.01763984772966321\n",
      "ID: 898ae8c4cee4e174980c7ecec1511b56c2fe9c8bf73d53f081f85e687bb57503 Parameters: {'nr_repeats': 3, 'top_n': 2} -> acc: 0.9647869674185463 ± 0.019449412820117928\n",
      "ID: c46bf2ca175501c7166e45336774246b679199de63e7fbba87cb1235d26f642f Parameters: {'nr_repeats': 5, 'top_n': 2} -> acc: 0.9647869674185463 ± 0.019449412820117928\n",
      "ID: 61c4c86dcd11a54e80a5d4a319c3e1c7e02902e3c8fa18a5590ae05864716c8d Parameters: {'nr_repeats': 7, 'top_n': 2} -> acc: 0.9647869674185463 ± 0.019449412820117928\n",
      "ID: 54508d1afe3874e61b26979efb4d7a0463b634145a3708b23a92dd2f6fd26d69 Parameters: {'nr_repeats': 9, 'top_n': 2} -> acc: 0.9647869674185463 ± 0.019449412820117928\n",
      "ID: bdecf02488b978bb5d5bc6c28e0d7fc194d9476ba0a6330eec9f167bfc5a2382 Parameters: {'nr_repeats': 3, 'top_n': 1} -> acc: 0.963063909774436 ± 0.018399328442981804\n",
      "ID: a326da4b2a854f873fa6d987e72c2a3155a13f0e655e6b249d64eb793c01df4f Parameters: {'nr_repeats': 5, 'top_n': 1} -> acc: 0.963063909774436 ± 0.018399328442981804\n",
      "ID: cb0017a08812b88581d7d9abad52709235c5966dad26602e90c0e2410412e339 Parameters: {'nr_repeats': 7, 'top_n': 1} -> acc: 0.963063909774436 ± 0.018399328442981804\n",
      "ID: 24c4e8b08d44523d1155e54c30f7166cf7e1715c24b0f84696084ec99d507c77 Parameters: {'nr_repeats': 9, 'top_n': 1} -> acc: 0.963063909774436 ± 0.018399328442981804\n"
     ]
    }
   ],
   "source": [
    "best_config_keys = sort_results(stack_results, 'acc', show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latex tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = load_json_file('../../results/hetero/lr_results.json')\n",
    "knn = load_json_file('../../results/hetero/knn_results.json')\n",
    "dt = load_json_file('../../results/hetero/dt_results.json')\n",
    "stack = load_json_file('../../results/hetero/stack_results.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_to_table_primer(result, top_n=5, metric='acc'):\n",
    "    top_keys = sort_results(result, metric, show=False)[:top_n]\n",
    "    avg_result = avg_results(result)\n",
    "    to_output = []\n",
    "    for k in top_keys:\n",
    "        temp = {}\n",
    "        temp['params'] = result[k]['params']\n",
    "        temp['mean_acc'] = avg_result[k]['mean_acc']\n",
    "        temp['std_acc'] = avg_result[k]['std_acc']\n",
    "        temp['mean_f1'] = avg_result[k]['mean_f1']\n",
    "        temp['std_f1'] = avg_result[k]['std_acc']\n",
    "        to_output.append(temp)\n",
    "    return to_output\n",
    "\n",
    "def results_to_table(result, top_n=5, metric='acc', title='Top performing KNN models', label='tab:results', decimals=4, width='\\\\textwidth'):\n",
    "    def esc(s):\n",
    "        return str(s).replace(\"_\", \"\\\\_\")\n",
    "    data = results_to_table_primer(result, top_n=top_n, metric=metric)\n",
    "    latex = \"\\\\begin{table}[H]\\n\"\n",
    "    latex += \"    \\\\centering\\n\"\n",
    "    latex += f\"    \\\\caption{{{title}}}\\n\"\n",
    "    latex += f\"    \\\\label{{{label}}}\\n\"\n",
    "    latex += f\"    \\\\begin{{tabularx}}{{{width}}}{{X r r}}\\n\"\n",
    "    latex += \"        \\\\toprule\\n\"\n",
    "    latex += \"        \\\\textbf{Parameters} & \\\\textbf{Accuracy} & \\\\textbf{F1-score} \\\\\\\\\\n\"\n",
    "    latex += \"        \\\\midrule\\n\"\n",
    "    for entry in data:\n",
    "        params = \", \".join([f\"{esc(k)}={esc(v)}\" for k, v in entry[\"params\"].items()])\n",
    "        params = f\"\\\\{{ \\\\texttt{{{params}}} \\\\}}\"\n",
    "        acc = f\"{entry['mean_acc']:.{decimals}f} ± {entry['std_acc']:.{decimals}f}\"\n",
    "        f1 = f\"{entry['mean_f1']:.{decimals}f} ± {entry['std_f1']:.{decimals}f}\"\n",
    "        latex += f\"        {params} & {acc} & {f1} \\\\\\\\\\n\"\n",
    "    latex += \"        \\\\bottomrule\\n\"\n",
    "    latex += \"    \\\\end{tabularx}\\n\"\n",
    "    latex += \"\\\\end{table}\"\n",
    "    return latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "    \\centering\n",
      "    \\caption{Top performing KNN models}\n",
      "    \\label{tab:KNN}\n",
      "    \\begin{tabularx}{\\textwidth}{X r r}\n",
      "        \\toprule\n",
      "        \\textbf{Parameters} & \\textbf{Accuracy} & \\textbf{F1-score} \\\\\n",
      "        \\midrule\n",
      "        \\{ \\texttt{n\\_neighbors=31, weights=uniform, algorithm=brute, p=1} \\} & 0.9385 ± 0.0286 & 0.9117 ± 0.0286 \\\\\n",
      "        \\{ \\texttt{n\\_neighbors=11, weights=uniform, algorithm=brute, p=1} \\} & 0.9350 ± 0.0236 & 0.9068 ± 0.0236 \\\\\n",
      "        \\{ \\texttt{n\\_neighbors=11, weights=distance, algorithm=brute, p=1} \\} & 0.9350 ± 0.0261 & 0.9067 ± 0.0261 \\\\\n",
      "        \\{ \\texttt{n\\_neighbors=31, weights=distance, algorithm=brute, p=1} \\} & 0.9332 ± 0.0270 & 0.9040 ± 0.0270 \\\\\n",
      "        \\{ \\texttt{n\\_neighbors=9, weights=uniform, algorithm=brute, p=1} \\} & 0.9332 ± 0.0258 & 0.9053 ± 0.0258 \\\\\n",
      "        \\bottomrule\n",
      "    \\end{tabularx}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "print(results_to_table(knn, title='Top performing KNN models', label=\"tab:KNN\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "    \\centering\n",
      "    \\caption{Top performing LR models}\n",
      "    \\label{tab:lr}\n",
      "    \\begin{tabularx}{\\textwidth}{X r r}\n",
      "        \\toprule\n",
      "        \\textbf{Parameters} & \\textbf{Accuracy} & \\textbf{F1-score} \\\\\n",
      "        \\midrule\n",
      "        \\{ \\texttt{penalty=l2, solver=lbfgs, C=100, class\\_weight=balanced, fit\\_intercept=True, max\\_iter=1000} \\} & 0.9596 ± 0.0209 & 0.9466 ± 0.0209 \\\\\n",
      "        \\{ \\texttt{penalty=l2, solver=lbfgs, C=100, class\\_weight=balanced, fit\\_intercept=True, max\\_iter=500} \\} & 0.9578 ± 0.0226 & 0.9444 ± 0.0226 \\\\\n",
      "        \\{ \\texttt{penalty=l2, solver=liblinear, C=100, class\\_weight=balanced, fit\\_intercept=True, max\\_iter=200} \\} & 0.9578 ± 0.0226 & 0.9444 ± 0.0226 \\\\\n",
      "        \\{ \\texttt{penalty=l2, solver=liblinear, C=100, class\\_weight=balanced, fit\\_intercept=True, max\\_iter=500} \\} & 0.9578 ± 0.0226 & 0.9444 ± 0.0226 \\\\\n",
      "        \\{ \\texttt{penalty=l2, solver=liblinear, C=100, class\\_weight=balanced, fit\\_intercept=True, max\\_iter=1000} \\} & 0.9578 ± 0.0226 & 0.9444 ± 0.0226 \\\\\n",
      "        \\bottomrule\n",
      "    \\end{tabularx}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "print(results_to_table(lr, title='Top performing LR models', label=\"tab:lr\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "    \\centering\n",
      "    \\caption{Top performing DT models}\n",
      "    \\label{tab:dt}\n",
      "    \\begin{tabularx}{\\textwidth}{X r r}\n",
      "        \\toprule\n",
      "        \\textbf{Parameters} & \\textbf{Accuracy} & \\textbf{F1-score} \\\\\n",
      "        \\midrule\n",
      "        \\{ \\texttt{criterion=gini, max\\_depth=None, min\\_samples\\_split=2, min\\_samples\\_leaf=2, max\\_features=sqrt, class\\_weight=balanced} \\} & 0.9472 ± 0.0240 & 0.9294 ± 0.0240 \\\\\n",
      "        \\{ \\texttt{criterion=gini, max\\_depth=10, min\\_samples\\_split=2, min\\_samples\\_leaf=2, max\\_features=sqrt, class\\_weight=balanced} \\} & 0.9472 ± 0.0240 & 0.9294 ± 0.0240 \\\\\n",
      "        \\{ \\texttt{criterion=gini, max\\_depth=20, min\\_samples\\_split=2, min\\_samples\\_leaf=2, max\\_features=sqrt, class\\_weight=balanced} \\} & 0.9472 ± 0.0240 & 0.9294 ± 0.0240 \\\\\n",
      "        \\{ \\texttt{criterion=gini, max\\_depth=30, min\\_samples\\_split=2, min\\_samples\\_leaf=2, max\\_features=sqrt, class\\_weight=balanced} \\} & 0.9472 ± 0.0240 & 0.9294 ± 0.0240 \\\\\n",
      "        \\{ \\texttt{criterion=gini, max\\_depth=5, min\\_samples\\_split=10, min\\_samples\\_leaf=4, max\\_features=sqrt, class\\_weight=balanced} \\} & 0.9455 ± 0.0328 & 0.9273 ± 0.0328 \\\\\n",
      "        \\bottomrule\n",
      "    \\end{tabularx}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "print(results_to_table(dt, title='Top performing DT models', label=\"tab:dt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "    \\centering\n",
      "    \\caption{Top performing stacking models}\n",
      "    \\label{tab:stack}\n",
      "    \\begin{tabularx}{\\textwidth}{X r r}\n",
      "        \\toprule\n",
      "        \\textbf{Parameters} & \\textbf{Accuracy} & \\textbf{F1-score} \\\\\n",
      "        \\midrule\n",
      "        \\{ \\texttt{nr\\_repeats=15, top\\_n=1} \\} & 0.9648 ± 0.0176 & 0.9528 ± 0.0176 \\\\\n",
      "        \\{ \\texttt{nr\\_repeats=25, top\\_n=1} \\} & 0.9648 ± 0.0176 & 0.9528 ± 0.0176 \\\\\n",
      "        \\{ \\texttt{nr\\_repeats=3, top\\_n=2} \\} & 0.9648 ± 0.0194 & 0.9524 ± 0.0194 \\\\\n",
      "        \\{ \\texttt{nr\\_repeats=5, top\\_n=2} \\} & 0.9648 ± 0.0194 & 0.9524 ± 0.0194 \\\\\n",
      "        \\{ \\texttt{nr\\_repeats=7, top\\_n=2} \\} & 0.9648 ± 0.0194 & 0.9524 ± 0.0194 \\\\\n",
      "        \\bottomrule\n",
      "    \\end{tabularx}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "print(results_to_table(stack, title='Top performing stacking models', label=\"tab:stack\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
