{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML441 Assignment 4\n",
    "## Charles de Kock - 26023830"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from contextlib import redirect_stdout\n",
    "from autorank import autorank, plot_stats\n",
    "import scikit_posthocs as sp\n",
    "import io\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef, accuracy_score\n",
    "import hashlib\n",
    "from collections import defaultdict\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 40\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxillary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_file(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        return json.load(file)\n",
    "    \n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        try:\n",
    "            return super().default(obj)\n",
    "        except TypeError:\n",
    "            pass\n",
    "        if hasattr(obj, '__dict__'):\n",
    "            return obj.__dict__\n",
    "        elif hasattr(obj, '__str__'):\n",
    "            return str(obj)\n",
    "        else:\n",
    "            return f\"<non-serializable: {type(obj).__name__}>\"\n",
    "\n",
    "def save_json(data, path, indent=4):\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(data, f, indent=indent, cls=CustomJSONEncoder)\n",
    "\n",
    "def hash_dict(d):\n",
    "    dict_str = json.dumps(d, sort_keys=True)\n",
    "    return hashlib.sha256(dict_str.encode('utf-8')).hexdigest()\n",
    "\n",
    "def avg_results(data, n_folds=10):\n",
    "    out = {}\n",
    "    for key in list(data.keys()):\n",
    "        accs = []\n",
    "        f1s = []\n",
    "        for i in range(n_folds):\n",
    "            temp = data[key]['results'][f'fold_{i}']\n",
    "            accs.append(temp['acc'])\n",
    "            f1s.append(temp['f1'])\n",
    "        out[key] =  {\n",
    "            'mean_acc': float(np.mean(accs)),\n",
    "            'std_acc': float(np.std(accs)),\n",
    "            'mean_f1': float(np.mean(f1s)),\n",
    "            'std_f1': float(np.std(f1s))\n",
    "        }\n",
    "    return out\n",
    "\n",
    "def sort_results(full_data, key, show=False, top_n=10):\n",
    "    avg_data = avg_results(full_data)\n",
    "    out = sorted(avg_data.keys(), key=lambda k: avg_data[k][f'mean_{key}'], reverse=True)\n",
    "    if show == True:\n",
    "        for r in out[:top_n]:\n",
    "            print(f\"ID: {r} Parameters: {full_data[r]['params']} -> {key}: {avg_data[r]['mean_' + key]} ± {avg_data[r]['std_' + key]}\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    y = df['diagnosis'].map({'B': 0, 'M': 1})\n",
    "    X = df.drop(columns=['diagnosis', 'gender', 'id'])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('breastCancer.csv', delimiter='\\t', na_values='?')\n",
    "X, y = preprocess(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_folds(X, y, n_folds = 10):\n",
    "    kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    folds = []\n",
    "    splits = kf.split(X, y)\n",
    "    for train_index, val_index in splits:\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        folds.append({'Xt': X_train, 'Xv': X_val, 'yt': y_train, 'yv': y_val})\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = generate_folds(X, y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_rf(fold, params):\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=params['n_estimators'],\n",
    "        criterion=params['criterion'],\n",
    "        max_depth=params['max_depth'],\n",
    "        min_samples_leaf=params['min_samples_leaf'],\n",
    "        max_features=params['max_features'],\n",
    "        class_weight=params['class_weight'],\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(fold['Xt'], fold['yt'])\n",
    "    y_pred = model.predict(fold['Xv'])\n",
    "    f1 = f1_score(fold['yv'], y_pred, average='binary')\n",
    "    acc = accuracy_score(fold['yv'], y_pred)\n",
    "    \n",
    "    return {'acc': acc, 'f1': f1}\n",
    "\n",
    "def create_param_dicts(**kwargs):\n",
    "    keys = list(kwargs.keys())\n",
    "    values = list(kwargs.values())\n",
    "    \n",
    "    param_dicts = []\n",
    "    for combination in itertools.product(*values):\n",
    "        param_dict = dict(zip(keys, combination))\n",
    "        param_dicts.append(param_dict)\n",
    "    \n",
    "    return param_dicts\n",
    "\n",
    "def run_experiment(param_dicts, folds):\n",
    "    out = {}\n",
    "    for p in tqdm(param_dicts):\n",
    "        entry = {}\n",
    "        entry['params'] = p\n",
    "        data = {}\n",
    "        for i in range(len(folds)):\n",
    "            data[f'fold_{i}'] = eval_rf(folds[i], p)\n",
    "        entry['results'] = data\n",
    "        out[hash_dict(p)] = entry\n",
    "    return out\n",
    "\n",
    "rf_param_dicts = create_param_dicts(\n",
    "    n_estimators=[100, 200, 300, 400, 500, 600],\n",
    "    max_depth=[None, 10, 20, 40],\n",
    "    min_samples_leaf=[1, 2, 4],\n",
    "    max_features=['sqrt', 'log2', 0.5],\n",
    "    class_weight=['balanced', None],\n",
    "    criterion=['gini', 'entropy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 540/540 [47:57<00:00,  5.33s/it]\n"
     ]
    }
   ],
   "source": [
    "rf_results = run_experiment(rf_param_dicts, folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(rf_results, '../../results/rf/no_preprocessing_results.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results = load_json_file('../../results/rf/no_preprocessing_results.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: b6d7e1674aeaaf67ec977afb53e5d88186ceca668721f38657b93e81c9ac9cc7 Parameters: {'n_estimators': 400, 'max_depth': None, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'class_weight': 'balanced', 'criterion': 'gini'} -> acc: 0.9630952380952381 ± 0.01831128961161411\n",
      "ID: a92261b8679df734cdf3326e44310bc465fd2ac812f6fe565562347b8671a7e8 Parameters: {'n_estimators': 400, 'max_depth': None, 'min_samples_leaf': 1, 'max_features': 'log2', 'class_weight': 'balanced', 'criterion': 'gini'} -> acc: 0.9630952380952381 ± 0.01831128961161411\n",
      "ID: e22a6549663f8b37c7ec464d1419734178fd18902275bef520a65d884d510155 Parameters: {'n_estimators': 400, 'max_depth': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'class_weight': 'balanced', 'criterion': 'gini'} -> acc: 0.9630952380952381 ± 0.01831128961161411\n",
      "ID: 372041f3f0141cee5fdc346a05bde5c54bc8a1f550027f7b88459935e23145dd Parameters: {'n_estimators': 400, 'max_depth': 10, 'min_samples_leaf': 1, 'max_features': 'log2', 'class_weight': 'balanced', 'criterion': 'gini'} -> acc: 0.9630952380952381 ± 0.01831128961161411\n",
      "ID: 282e935439aa20953ba9fc228584569633506eb53d4ccaf569fa6c53ba71f341 Parameters: {'n_estimators': 400, 'max_depth': 20, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'class_weight': 'balanced', 'criterion': 'gini'} -> acc: 0.9630952380952381 ± 0.01831128961161411\n",
      "ID: 360fbf3ee31b6187ee73584296299ae32d5b015ec1a1c7e78fc0a9d362823229 Parameters: {'n_estimators': 400, 'max_depth': 20, 'min_samples_leaf': 1, 'max_features': 'log2', 'class_weight': 'balanced', 'criterion': 'gini'} -> acc: 0.9630952380952381 ± 0.01831128961161411\n",
      "ID: 1d040296f5e8307d9e838bbcb9783fe4c7da04c4f51f3e0f6edd5030cce7e250 Parameters: {'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'class_weight': 'balanced', 'criterion': 'entropy'} -> acc: 0.963095238095238 ± 0.016545268960122206\n",
      "ID: 78f69aa125e94060eb86c7fdedccdca91f7737f191665acbcb498f8f0bfa2b90 Parameters: {'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 1, 'max_features': 'log2', 'class_weight': 'balanced', 'criterion': 'entropy'} -> acc: 0.963095238095238 ± 0.016545268960122206\n",
      "ID: 11b4f82c3db0ab8d012c144a5843c098273f954ae7a4366b96916218ffb214f7 Parameters: {'n_estimators': 50, 'max_depth': None, 'min_samples_leaf': 4, 'max_features': 0.5, 'class_weight': None, 'criterion': 'entropy'} -> acc: 0.963095238095238 ± 0.01992136364604669\n",
      "ID: 3b0f6af006c71dca0b6cdaf4e073178e7b21e88430b960de8f04692289f53a2c Parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'class_weight': 'balanced', 'criterion': 'entropy'} -> acc: 0.963095238095238 ± 0.016545268960122206\n"
     ]
    }
   ],
   "source": [
    "best_config_keys = sort_results(rf_results, 'acc', show=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
