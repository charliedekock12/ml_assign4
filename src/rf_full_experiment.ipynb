{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML441 Assignment 4\n",
    "## Charles de Kock - 26023830"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "from contextlib import redirect_stdout\n",
    "from autorank import autorank, plot_stats\n",
    "import scikit_posthocs as sp\n",
    "import io\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, matthews_corrcoef, accuracy_score\n",
    "import hashlib\n",
    "from collections import defaultdict\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 40\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auxillary Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_json_file(filename):\n",
    "    with open(filename, 'r') as file:\n",
    "        return json.load(file)\n",
    "    \n",
    "class CustomJSONEncoder(json.JSONEncoder):\n",
    "    def default(self, obj):\n",
    "        try:\n",
    "            return super().default(obj)\n",
    "        except TypeError:\n",
    "            pass\n",
    "        if hasattr(obj, '__dict__'):\n",
    "            return obj.__dict__\n",
    "        elif hasattr(obj, '__str__'):\n",
    "            return str(obj)\n",
    "        else:\n",
    "            return f\"<non-serializable: {type(obj).__name__}>\"\n",
    "\n",
    "def save_json(data, path, indent=4):\n",
    "    with open(path, \"w\") as f:\n",
    "        json.dump(data, f, indent=indent, cls=CustomJSONEncoder)\n",
    "\n",
    "def hash_dict(d):\n",
    "    dict_str = json.dumps(d, sort_keys=True)\n",
    "    return hashlib.sha256(dict_str.encode('utf-8')).hexdigest()\n",
    "\n",
    "def avg_results(data, n_folds=10):\n",
    "    out = {}\n",
    "    for key in list(data.keys()):\n",
    "        accs = []\n",
    "        f1s = []\n",
    "        for i in range(n_folds):\n",
    "            temp = data[key]['results'][f'fold_{i}']\n",
    "            accs.append(temp['acc'])\n",
    "            f1s.append(temp['f1'])\n",
    "        out[key] =  {\n",
    "            'mean_acc': float(np.mean(accs)),\n",
    "            'std_acc': float(np.std(accs)),\n",
    "            'mean_f1': float(np.mean(f1s)),\n",
    "            'std_f1': float(np.std(f1s))\n",
    "        }\n",
    "    return out\n",
    "\n",
    "def sort_results(full_data, key, show=False, top_n=10):\n",
    "    avg_data = avg_results(full_data)\n",
    "    out = sorted(avg_data.keys(), key=lambda k: avg_data[k][f'mean_{key}'], reverse=True)\n",
    "    if show == True:\n",
    "        for r in out[:top_n]:\n",
    "            print(f\"ID: {r} Parameters: {full_data[r]['params']} -> {key}: {avg_data[r]['mean_' + key]} ± {avg_data[r]['std_' + key]}\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    y = df['diagnosis'].map({'B': 0, 'M': 1})\n",
    "    X = df.drop(columns=['diagnosis', 'gender', 'id'])\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../data/breastCancer.csv', delimiter='\\t', na_values='?')\n",
    "X, y = preprocess(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross validation folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_folds(X, y, n_folds = 10):\n",
    "    kf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
    "    folds = []\n",
    "    splits = kf.split(X, y)\n",
    "    for train_index, val_index in splits:\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        folds.append({'Xt': X_train, 'Xv': X_val, 'yt': y_train, 'yv': y_val})\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "folds = generate_folds(X, y, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_rf(fold, params):\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=params['n_estimators'],\n",
    "        criterion=params['criterion'],\n",
    "        max_depth=params['max_depth'],\n",
    "        min_samples_leaf=params['min_samples_leaf'],\n",
    "        max_features=params['max_features'],\n",
    "        class_weight=params['class_weight'],\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "    \n",
    "    model.fit(fold['Xt'], fold['yt'])\n",
    "    y_pred = model.predict(fold['Xv'])\n",
    "    f1 = f1_score(fold['yv'], y_pred, average='binary')\n",
    "    acc = accuracy_score(fold['yv'], y_pred)\n",
    "    \n",
    "    return {'acc': acc, 'f1': f1}\n",
    "\n",
    "def create_param_dicts(**kwargs):\n",
    "    keys = list(kwargs.keys())\n",
    "    values = list(kwargs.values())\n",
    "    \n",
    "    param_dicts = []\n",
    "    for combination in itertools.product(*values):\n",
    "        param_dict = dict(zip(keys, combination))\n",
    "        param_dicts.append(param_dict)\n",
    "    \n",
    "    return param_dicts\n",
    "\n",
    "def run_experiment(param_dicts, folds):\n",
    "    out = {}\n",
    "    for p in tqdm(param_dicts):\n",
    "        entry = {}\n",
    "        entry['params'] = p\n",
    "        data = {}\n",
    "        for i in range(len(folds)):\n",
    "            data[f'fold_{i}'] = eval_rf(folds[i], p)\n",
    "        entry['results'] = data\n",
    "        out[hash_dict(p)] = entry\n",
    "    return out\n",
    "\n",
    "rf_param_dicts = create_param_dicts(\n",
    "    n_estimators=[100, 200, 300, 400, 500, 600],\n",
    "    max_depth=[None, 10, 20, 40],\n",
    "    min_samples_leaf=[1, 2, 4],\n",
    "    max_features=['sqrt', 'log2', 0.5],\n",
    "    class_weight=['balanced', None],\n",
    "    criterion=['gini', 'entropy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/864 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 864/864 [1:32:03<00:00,  6.39s/it]\n"
     ]
    }
   ],
   "source": [
    "rf_results = run_experiment(rf_param_dicts, folds)\n",
    "save_json(rf_results, '../../results/rf/rf_results.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(rf_results, '../../results/rf/rf_results.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_results = load_json_file('../../results/rf/rf_results.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 088b164bcfb804169f292b098628e2a8db6e4923e64646a6a0e81ba6acc223bc Parameters: {'n_estimators': 500, 'max_depth': None, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'class_weight': 'balanced', 'criterion': 'gini'} -> acc: 0.9666040100250626 ± 0.014581776929294759\n",
      "ID: 872be7e21374c7637fa0d6660119bd5457ed101eb1867b17d4078fb484220694 Parameters: {'n_estimators': 500, 'max_depth': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'class_weight': 'balanced', 'criterion': 'gini'} -> acc: 0.9666040100250626 ± 0.014581776929294759\n",
      "ID: ec7a246568b4eccd6933f6393a9acf09d420f32020e876f234aff635c7d019fa Parameters: {'n_estimators': 500, 'max_depth': 20, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'class_weight': 'balanced', 'criterion': 'gini'} -> acc: 0.9666040100250626 ± 0.014581776929294759\n",
      "ID: d301ed1aca94a6e06ef4fe70eedf0d5b062830536ad0c460a0026075a693f01a Parameters: {'n_estimators': 500, 'max_depth': 40, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'class_weight': 'balanced', 'criterion': 'gini'} -> acc: 0.9666040100250626 ± 0.014581776929294759\n",
      "ID: 89c8889ab538427b9b6523ad8a3b193f3502070f4684445adbe5fe2dc5c369c2 Parameters: {'n_estimators': 200, 'max_depth': None, 'min_samples_leaf': 1, 'max_features': 0.5, 'class_weight': 'balanced', 'criterion': 'entropy'} -> acc: 0.9648496240601503 ± 0.017544866601965192\n",
      "ID: 0445995ee54f8b08dcfccd453c3889efaa2bcc148c05d9b8f707f1b93efdb0d3 Parameters: {'n_estimators': 200, 'max_depth': 10, 'min_samples_leaf': 1, 'max_features': 0.5, 'class_weight': 'balanced', 'criterion': 'entropy'} -> acc: 0.9648496240601503 ± 0.017544866601965192\n",
      "ID: bbcaf0dcc6b923bbcf1e785c7b5d315704dcdade4f49bda4a2505c40f07165f6 Parameters: {'n_estimators': 200, 'max_depth': 20, 'min_samples_leaf': 1, 'max_features': 0.5, 'class_weight': 'balanced', 'criterion': 'entropy'} -> acc: 0.9648496240601503 ± 0.017544866601965192\n",
      "ID: fedf162304107b7035471e269a252be34a86e54628415daa4b9fd39b4515684a Parameters: {'n_estimators': 200, 'max_depth': 40, 'min_samples_leaf': 1, 'max_features': 0.5, 'class_weight': 'balanced', 'criterion': 'entropy'} -> acc: 0.9648496240601503 ± 0.017544866601965192\n",
      "ID: 00c61ccc1688afe4edac7aecc2b930955f8c6e7542d303d55206da7e98d3bfb2 Parameters: {'n_estimators': 600, 'max_depth': None, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'class_weight': 'balanced', 'criterion': 'gini'} -> acc: 0.9648496240601503 ± 0.013590715195511421\n",
      "ID: 22dda01d5b1c8069330cdf1172cc13df72facba75c9c232cabd01998cabaa00e Parameters: {'n_estimators': 600, 'max_depth': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'class_weight': 'balanced', 'criterion': 'gini'} -> acc: 0.9648496240601503 ± 0.013590715195511421\n"
     ]
    }
   ],
   "source": [
    "best_config_keys = sort_results(rf_results, 'acc', show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latex tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results_to_table_primer(result, top_n=5, metric='acc'):\n",
    "    top_keys = sort_results(result, metric, show=False)[:top_n]\n",
    "    avg_result = avg_results(result)\n",
    "    to_output = []\n",
    "    for k in top_keys:\n",
    "        temp = {}\n",
    "        temp['params'] = result[k]['params']\n",
    "        temp['mean_acc'] = avg_result[k]['mean_acc']\n",
    "        temp['std_acc'] = avg_result[k]['std_acc']\n",
    "        temp['mean_f1'] = avg_result[k]['mean_f1']\n",
    "        temp['std_f1'] = avg_result[k]['std_acc']\n",
    "        to_output.append(temp)\n",
    "    return to_output\n",
    "\n",
    "def results_to_table(result, top_n=5, metric='acc', title='Top performing KNN models', label='tab:results', decimals=4, width='\\\\textwidth'):\n",
    "    def esc(s):\n",
    "        return str(s).replace(\"_\", \"\\\\_\")\n",
    "    data = results_to_table_primer(result, top_n=top_n, metric=metric)\n",
    "    latex = \"\\\\begin{table}[H]\\n\"\n",
    "    latex += \"    \\\\centering\\n\"\n",
    "    latex += f\"    \\\\caption{{{title}}}\\n\"\n",
    "    latex += f\"    \\\\label{{{label}}}\\n\"\n",
    "    latex += f\"    \\\\begin{{tabularx}}{{{width}}}{{X r r}}\\n\"\n",
    "    latex += \"        \\\\toprule\\n\"\n",
    "    latex += \"        \\\\textbf{Parameters} & \\\\textbf{Accuracy} & \\\\textbf{F1-score} \\\\\\\\\\n\"\n",
    "    latex += \"        \\\\midrule\\n\"\n",
    "    for entry in data:\n",
    "        params = \", \".join([f\"{esc(k)}={esc(v)}\" for k, v in entry[\"params\"].items()])\n",
    "        params = f\"\\\\{{ \\\\texttt{{{params}}} \\\\}}\"\n",
    "        acc = f\"{entry['mean_acc']:.{decimals}f} ± {entry['std_acc']:.{decimals}f}\"\n",
    "        f1 = f\"{entry['mean_f1']:.{decimals}f} ± {entry['std_f1']:.{decimals}f}\"\n",
    "        latex += f\"        {params} & {acc} & {f1} \\\\\\\\\\n\"\n",
    "    latex += \"        \\\\bottomrule\\n\"\n",
    "    latex += \"    \\\\end{tabularx}\\n\"\n",
    "    latex += \"\\\\end{table}\"\n",
    "    return latex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\n",
      "    \\centering\n",
      "    \\caption{Top performing RF models}\n",
      "    \\label{tab:rf}\n",
      "    \\begin{tabularx}{\\textwidth}{X r r}\n",
      "        \\toprule\n",
      "        \\textbf{Parameters} & \\textbf{Accuracy} & \\textbf{F1-score} \\\\\n",
      "        \\midrule\n",
      "        \\{ \\texttt{n\\_estimators=500, max\\_depth=None, min\\_samples\\_leaf=1, max\\_features=sqrt, class\\_weight=balanced, criterion=gini} \\} & 0.9666 ± 0.0146 & 0.9549 ± 0.0146 \\\\\n",
      "        \\{ \\texttt{n\\_estimators=500, max\\_depth=10, min\\_samples\\_leaf=1, max\\_features=sqrt, class\\_weight=balanced, criterion=gini} \\} & 0.9666 ± 0.0146 & 0.9549 ± 0.0146 \\\\\n",
      "        \\{ \\texttt{n\\_estimators=500, max\\_depth=20, min\\_samples\\_leaf=1, max\\_features=sqrt, class\\_weight=balanced, criterion=gini} \\} & 0.9666 ± 0.0146 & 0.9549 ± 0.0146 \\\\\n",
      "        \\{ \\texttt{n\\_estimators=500, max\\_depth=40, min\\_samples\\_leaf=1, max\\_features=sqrt, class\\_weight=balanced, criterion=gini} \\} & 0.9666 ± 0.0146 & 0.9549 ± 0.0146 \\\\\n",
      "        \\{ \\texttt{n\\_estimators=200, max\\_depth=None, min\\_samples\\_leaf=1, max\\_features=0.5, class\\_weight=balanced, criterion=entropy} \\} & 0.9648 ± 0.0175 & 0.9524 ± 0.0175 \\\\\n",
      "        \\bottomrule\n",
      "    \\end{tabularx}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "print(results_to_table(rf_results, title='Top performing RF models', label='tab:rf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
